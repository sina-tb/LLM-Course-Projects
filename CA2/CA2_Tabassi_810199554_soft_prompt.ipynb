{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnEUrLq1-kp"
      },
      "source": [
        "## CA 2, LLMs Spring 2024\n",
        "\n",
        "- **Name: Sina Tabassi**\n",
        "- **Student ID: 810199554**\n",
        "\n",
        "---\n",
        "#### Your submission should be named using the following format: `CA2_LASTNAME_STUDENTID_soft_prompt.ipynb`.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---\n",
        "\n",
        "If you have any further questions or concerns, contact the TA via email:\n",
        "mohammad136631@gmail.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfrgatGB3Aac"
      },
      "source": [
        "# What are Soft prompts?\n",
        "Soft prompts are learnable tensors concatenated with the input embeddings that can be optimized to a dataset; the downside is that they aren’t human readable because you aren’t matching these “virtual tokens” to the embeddings of a real word.\n",
        "<br>\n",
        "<div>\n",
        "<img src=\"https://www.researchgate.net/publication/366062946/figure/fig1/AS:11431281105340756@1670383256990/The-comparison-between-the-previous-T5-prompt-tuning-method-part-a-and-the-introduced.jpg\"/>\n",
        "</div>\n",
        "\n",
        "Read More:\n",
        "<br>[Youtube : PEFT and Soft Prompt](https://www.youtube.com/watch?v=8uy_WII76L0)\n",
        "<br>[Paper: The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "https://arxiv.org/pdf/2101.00190.pdf\n",
        "<br>[Paper: Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLaYIRN4X7cC"
      },
      "source": [
        "# Part 1 (20 Points)\n",
        "Before diving into the practical applications, let's first ensure your foundational knowledge is solid. Please answer the following questions.\n",
        "\n",
        "**A) Compare and contrast model tuning and prompt tuning in terms of their effectiveness for specific downstream tasks. (5 Points)**\n",
        "\n",
        "*Answer:*\n",
        "\n",
        "Let us compare the efficacy of each approach:\n",
        "- Model tuning tends to be effective when the downstream task is significantly different from the tasks the model was originally trained on. It allows the model to adapt its representations to better suit the task-specific data. For example, if the downstream task involves sentiment analysis on financial documents, fine-tuning a pre-trained language model on a dataset of financial news articles can lead to improved performance.\n",
        "\n",
        "- Prompt tuning can be effective when the downstream task shares similarities with the tasks the model was originally trained on. By providing task-specific prompts, the model can leverage its pre-existing knowledge and fine-tune its responses without requiring extensive retraining. For instance, in question-answering tasks, providing well-crafted prompts tailored to the context of the questions can lead to improved accuracy without the need for extensive fine-tuning.\n",
        "\n",
        "\n",
        "Additionally, according to `The Power of Scale for Parameters-Efficient Prompt Tuning` paper, in big models with over 10^10 parameters, we pretty much get the same results whether we use model-tuning or Prompt tuning. But in smaller models, we can't match the results of these two approaches, and Prompt tuning tends to have lower SuperGLUE scores compared to model-tuning methods. However, as we crank up the model parameters, the difference in their SuperGLUE scores starts to shrink.\n",
        "\n",
        "\n",
        "**B) Explore the challenges associated with interpreting soft prompts in the continuous embedding space and propose potential solutions. (5 Points)**\n",
        "\n",
        "*Answer:*\n",
        "\n",
        "Challenges:\n",
        "\n",
        "- Soft prompts can be ambiguous and may not provide clear guidance to the model, leading to inconsistent or suboptimal responses.\n",
        "\n",
        "- The continuous embedding space is high-dimensional and complex, making it difficult to interpret the relationships between soft prompts and model outputs.\n",
        "\n",
        "- Soft prompts may suffer from semantic drift, where the model's interpretation of the prompt diverges from the intended meaning over time or across different contexts.\n",
        "\n",
        "- Soft prompts may not generalize well across different domains or datasets, requiring adaptation to new contexts.\n",
        "\n",
        "Potential Soulutions:\n",
        "\n",
        "- Incorporate additional context or constraints to disambiguate soft prompts. This could involve providing more specific instructions or examples alongside the soft prompt to guide the model towards the desired interpretation.\n",
        "\n",
        "- Employ visualization techniques to explore and understand the embedding space. Dimensionality reduction methods such as t-SNE or UMAP can help visualize the relationships between soft prompts and embeddings, providing insights into the model's behavior.\n",
        "\n",
        "- Continuously monitor and update soft prompts to ensure they remain relevant and effective. Fine-tuning the model on new data or periodically retraining with updated prompts can help mitigate semantic drift and maintain performance.\n",
        "\n",
        "- Utilize techniques for domain adaptation, such as adversarial training, domain-specific fine-tuning, or data augmentation with domain-relevant examples. This can help the model adapt to new domains while maintaining the effectiveness of soft prompts.\n",
        "\n",
        "**C) What is the effect of initializing prompts randomly versus initializing them from the vocabulary, and how does this impact the performance of prompt tuning? (5 Points)**\n",
        "\n",
        "*Answer:*\n",
        "\n",
        "First, let's compare the impact of each approach:\n",
        "- When prompts are initialized randomly, they lack any inherent semantic meaning or relevance to the downstream task.\n",
        "-Initializing prompts from the vocabulary involves selecting words or phrases from the model's vocabulary that are likely to be relevant to the downstream task.\n",
        "\n",
        "Now, let's examine their influence on the performance of prompt tuning:\n",
        "- Randomly initialized prompts may lead to suboptimal performance initially since they provide no useful guidance to the model. The model has to learn to associate the randomly initialized prompt with the desired task, which can be challenging and may require more training data and time.\n",
        "-Initializing prompts from the vocabulary provides the model with a starting point that is more likely to be semantically meaningful and relevant to the task. This can lead to faster convergence and better performance compared to randomly initialized prompts.\n",
        "\n",
        "\n",
        "Furthermore, as detailed in `The Power of Scale for Parameters-Efficient Prompt Tuning` the utilization of random uniform initialization falls behind compared to initializations employing sampled vocabulary or class label embeddings. However, as the number of parameters escalates to 10^10, this discrepancy diminishes.\n",
        "\n",
        "\n",
        "**D) How is the optimization process in the prefix tuning(<br>[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)) and Why did they use this technique? (5 Points)**\n",
        "\n",
        "*Answer:*\n",
        "\n",
        "\n",
        "In prefix-tuning, we maintain the model's original parameters unchanged while introducing additional vectors to the model, serving as prefixes for the input. These vectors, added individually for each transformer block and known as virtual tokens, are then updated or fine-tuned for a specific task. This methodology, which impacts only a small fraction of the model's parameters, achieves performance on par with full data fine-tuning, surpasses fine-tuning in scenarios with limited data, and exhibits superior generalization to examples featuring unseen topics during training.\n",
        "\n",
        "There are several advantages to employing this technique:\n",
        "- Its modular nature allows for seamless adaptation to entirely different tasks simply by replacing prefixes. In contrast, fine-tuning necessitates replacing the model with another instance fine-tuned for the new task, preventing the sharing of the same model across different tasks.\n",
        "- It is lightweight and demands lower resources compared to full fine-tuning since it entails updating far fewer parameters than fine-tuning.\n",
        "- The authors applied prefix-tuning on GPT-2 for table-to-text generation and on BART for summarization, demonstrating its effectiveness across diverse natural language generation tasks.\n",
        "- It enables the formulation of more expressive prompts owing to continuous optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMgi75DV-bo"
      },
      "source": [
        "# Part 2 (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3gjmZROpLP5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZG_yY6ep9C7S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_UcfBmLpRiJ"
      },
      "source": [
        "## Model Selection & Constants\n",
        "We will use `bert-fa-base-uncased` as our base model from Hugging Face ([HF_Link](https://huggingface.co/HooshvareLab/bert-fa-base-uncased)). For our tuning, we intend to utilize 20 soft prompt tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mV2aP8bwV-z5"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    seed = 42\n",
        "    max_len = 128\n",
        "    train_batch = 16\n",
        "    valid_batch = 32\n",
        "    epochs = 10\n",
        "    n_tokens=20\n",
        "    learning_rate = 0.01\n",
        "    model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0asPslpkSh"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset contains around 7000 Persian sentences and their corresponding polarity, and have been manually classified into 5 categories (i.e. Angry)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpsgvYumvNa"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -q\n",
        "\n",
        "!gdown 1BT9G7y5YyyN9nlRzf0iQhtAnIZvftIs5 -O softprompt_dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX4IHS-JhQBg",
        "outputId": "3436a3da-2d07-48bc-803a-d2c22dee0c75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BT9G7y5YyyN9nlRzf0iQhtAnIZvftIs5\n",
            "To: /content/softprompt_dataset.csv\n",
            "\r  0% 0.00/1.29M [00:00<?, ?B/s]\r100% 1.29M/1.29M [00:00<00:00, 164MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2JmHJ2wpoaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = \"softprompt_dataset.csv\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmviyjCrz6mi"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PITqCGDx0McE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49515ccd-83b1-49ee-d8de-4c7c0b17e0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clean-text[gpl] in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from clean-text[gpl]) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from clean-text[gpl]) (6.2.0)\n",
            "Requirement already satisfied: unidecode<2.0.0,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from clean-text[gpl]) (1.3.8)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]) (0.2.13)\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.2)\n",
            "Requirement already satisfied: flashtext<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from hazm) (2.7)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.2)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.24.3)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.10)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U clean-text[gpl]\n",
        "%pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U0Nlfm0qE_1P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from cleantext import clean\n",
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k4CFqPaV0Pqp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    text = cleanhtml(text)\n",
        "\n",
        "    # normalizing\n",
        "    #normalizer = hazm.Normalizer()\n",
        "    #text = normalizer.normalize(text)\n",
        "\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "\n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z_5ZyotA0cxw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def parallel_apply_with_progress(df, func, n_workers=4):\n",
        "    with ThreadPoolExecutor(max_workers=n_workers) as executor, tqdm(total=len(df)) as pbar:\n",
        "        def update(*args):\n",
        "            pbar.update()\n",
        "\n",
        "        results = []\n",
        "        for result in executor.map(func, df['text']):\n",
        "            results.append(result)\n",
        "            update()\n",
        "\n",
        "        df['text'] = pd.Series(results)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUjLG3E0qxK",
        "outputId": "c379d61d-74b9-482b-f2f1-d4a031cc18e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7023/7023 [00:04<00:00, 1533.52it/s]\n"
          ]
        }
      ],
      "source": [
        "df = parallel_apply_with_progress(df, cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_2tZk2fBSwJL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "train_df = df.loc[X_train]\n",
        "validation_df = df.loc[X_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTgl8-RV926",
        "outputId": "76de3a68-cf75-4458-bb9e-b0aaa3b6b6c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, -1: 3, -2: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "possible_labels = df.label.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IgTnO4ctWKqo"
      },
      "outputs": [],
      "source": [
        "train_df['label'] = train_df.label.replace(label_dict)\n",
        "validation_df['label'] = validation_df.label.replace(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqIWHJ9XMiOr"
      },
      "source": [
        "### Create Dataset Class (5 Points)\n",
        "In this step we will getting our dataset ready for training.\n",
        "\n",
        "In this part we will define BERT-based dataset class for text classification, with configuration parameters. It preprocesses text data and tokenizes it using the BERT tokenizer.\n",
        "\n",
        "\n",
        "Complete the preprocessing step in the __getitem__ method by adding padding tokens to 'input_ids' and 'attention_mask',\n",
        "The count of this pad tokens is the same as `n_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CyS6DyeZ75bZ"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.text = df['text'].values\n",
        "        self.labels = df['label'].values\n",
        "        self.all_labels = [0, 1, 2, 3, 4]\n",
        "        self.max_len = CONFIG.max_len\n",
        "        self.tokenizer = CONFIG.tokenizer\n",
        "        self.n_tokens=CONFIG.n_tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = ' '.join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ######### Your code begins #########\n",
        "        inputs['input_ids'] = inputs['input_ids'] + [self.tokenizer.pad_token_id] * self.n_tokens\n",
        "        inputs['attention_mask'] = inputs['attention_mask'] + [0] * self.n_tokens\n",
        "        ######### Your code ends ###########\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        label_dict = {label: (label == labels) for label in self.all_labels}\n",
        "        labels_tensor = torch.tensor([float(label_dict[label]) for label in self.all_labels])\n",
        "        return {\n",
        "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "            'label': labels_tensor\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qf8AYo8cFiud"
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataset(train_df)\n",
        "validation_dataset = BERTDataset(validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSWkTORNcxvx"
      },
      "source": [
        "## Define Prompt Embedding Layer (15 Points)\n",
        "In this part we will define our prompt layer in `PROMPTEmbedding` module.\n",
        "\n",
        "\n",
        "<font color='#73FF73'><b>You have to complete</b></font> `initialize_embedding` and  `forward` <font color='#73FF73'><b>functions.</b></font>\n",
        "\n",
        "In `initialize_embedding` function initialize the learned embeddings based on whether they should be initialized from the vocabulary or randomly within the specified range.\n",
        "\n",
        "In `forward` function, modify the input_embedding to extract the relevant part based on n_tokens.\n",
        "\n",
        "Repeat the learned_embedding to match the size of input_embedding.\n",
        "\n",
        "Concatenate the learned_embedding and input_embedding properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6tqAU4Ubj2t8"
      },
      "outputs": [],
      "source": [
        "class PROMPTEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                emb_layer: nn.Embedding,\n",
        "                n_tokens: int = 20,\n",
        "                random_range: float = 0.5,\n",
        "                initialize_from_vocab: bool = True):\n",
        "\n",
        "      super(PROMPTEmbedding, self).__init__()\n",
        "      self.emb_layer = emb_layer\n",
        "      self.n_tokens = n_tokens\n",
        "      self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(emb_layer,\n",
        "                                                                               n_tokens,\n",
        "                                                                               random_range,\n",
        "                                                                               initialize_from_vocab))\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             emb_layer: nn.Embedding,\n",
        "                             n_tokens: int = 20,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "\n",
        "      if initialize_from_vocab:\n",
        "        ######### Your code begins #########\n",
        "        embedding = emb_layer.weight[:n_tokens].clone().detach()\n",
        "\n",
        "      else:\n",
        "        embedding = torch.rand((n_tokens, emb_layer.weight.size(1))) * random_range\n",
        "        ######### Your code ends ###########\n",
        "      return embedding\n",
        "\n",
        "\n",
        "    def forward(self, tokens):\n",
        "      ######### Your code begins #########\n",
        "      input_embedding = self.emb_layer(tokens[:, self.n_tokens:])\n",
        "      learned_embedding = self.learned_embedding.repeat(tokens.size(0), 1, 1)\n",
        "      joined_embedding = torch.cat((learned_embedding, input_embedding), dim=1)\n",
        "      ######### Your code ends ###########\n",
        "      return joined_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhES_23bDfXZ"
      },
      "source": [
        "## Replace model's embedding layer with our layer (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-AMhjuooOQKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f21bfde816a44bda9ff7e01ecf85d735",
            "ba964d1bb5cd4bdf9e97c1e11ab8189a",
            "4b31a8abc501456f8ec737a265bb18c3",
            "7e3e74c8b15a4bb78a76a346fa2526e2",
            "bfca75c98a344a96a1cab791f90620c6",
            "bf9d42243fe544eb9943c2d424a96a1f",
            "60c9cbd754ca4af2b802e8a1e2083924",
            "a0e1003f687241c9a30463d436d98115",
            "f6744263251a44d88662e6fe223dcf06",
            "eb71ec5662164879ac517842b2c388eb",
            "88bfd33c5b5049e087ef70e9a9481e09"
          ]
        },
        "outputId": "1349be90-9191-4a2e-95e3-822369628b73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f21bfde816a44bda9ff7e01ecf85d735"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define your BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False).to(CONFIG.device)\n",
        "######### Your code begins #########\n",
        "embeddings = PROMPTEmbedding(model.get_input_embeddings(),n_tokens=CONFIG.n_tokens).to(CONFIG.device)\n",
        "model.set_input_embeddings(embeddings)\n",
        "######### Your code ends ###########\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wlsc2meajrn"
      },
      "source": [
        "## Freezing Model Parameters (5 points)\n",
        "In this part we will freeze entire model except `learned_embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3CCq8Z1lajGC"
      },
      "outputs": [],
      "source": [
        "######### Your code begins #########\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    if \"learned_embedding\" in name:\n",
        "      param.requires_grad = True\n",
        "######### Your code ends ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ud-O_Rrptq"
      },
      "source": [
        "## Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1IckuDmDWRye"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17S9KFKM1jgP"
      },
      "source": [
        "## Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsfsyKAY2yu"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mVRa2SLDWUM9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=CONFIG.valid_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Sj5pT6ZDbz"
      },
      "source": [
        "### Define evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3f-OVsQ5_War"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-bqs9Hxi9yjz"
      },
      "outputs": [],
      "source": [
        "def evaluate(val_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "        logits = outputs[\"logits\"]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(val_dataloader)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjO1TwDSZMWH"
      },
      "source": [
        "### Define trainng loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xjXZ7oB_1jGv"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_dataloader, val_dataloader):\n",
        "\n",
        "    epochs = CONFIG.epochs\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      loss_train_total = 0\n",
        "\n",
        "      progress_bar = tqdm(train_loader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=True)\n",
        "\n",
        "      for batch in progress_bar:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                }\n",
        "\n",
        "        output = model(**inputs)\n",
        "\n",
        "        loss = output[\"loss\"]\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "      tqdm.write(f'\\nEpoch {epoch}')\n",
        "      loss_train_avg = loss_train_total/len(train_loader)\n",
        "      tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "\n",
        "      val_loss, predictions, true_vals = evaluate(val_dataloader)\n",
        "      val_f1 = f1_score_func(predictions, true_vals)\n",
        "      tqdm.write(f'Validation loss: {val_loss}')\n",
        "      tqdm.write(f'F1 Score (Weighted): {val_f1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTI1yeyZW1i"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "--yqi1tp1jCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d7fe23-095a-4eb5-e686-46a8d1c501fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [01:34<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.47132693573752826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:43<15:35, 103.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.457704509749557\n",
            "F1 Score (Weighted): 0.22338408832786694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [03:24<15:35, 103.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.46188399793311236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [03:34<14:22, 107.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4566034728830511\n",
            "F1 Score (Weighted): 0.23017403352191465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [05:17<14:22, 107.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4599987838198157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [05:28<12:53, 110.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4558577338854472\n",
            "F1 Score (Weighted): 0.2300164086062059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [07:12<12:53, 110.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.45941353704840104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [07:22<11:12, 112.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.455285673791712\n",
            "F1 Score (Weighted): 0.28749387201808313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [09:08<11:12, 112.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.4578447753095372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [09:18<09:27, 113.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4546360508962111\n",
            "F1 Score (Weighted): 0.225711626302008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [11:03<09:27, 113.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.457851216914182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [11:14<07:36, 114.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.45350095178141736\n",
            "F1 Score (Weighted): 0.2727268796374769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [12:59<07:36, 114.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.45811651447877527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [13:09<05:43, 114.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.45096983602552704\n",
            "F1 Score (Weighted): 0.299107584812588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:55<05:43, 114.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.4562078213149851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [15:05<03:49, 114.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.453257166074984\n",
            "F1 Score (Weighted): 0.21387945384138884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [16:50<03:49, 114.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.45561252016434695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [17:00<01:55, 115.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.45107919609907904\n",
            "F1 Score (Weighted): 0.25153692297102614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [18:45<01:55, 115.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.4548560521181892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [18:56<00:00, 113.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.45061438824191236\n",
            "F1 Score (Weighted): 0.2688565013399141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_3FYFfIUKeE"
      },
      "source": [
        "## Using OpenDelta library (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yp3_9J0wUBxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133bc616-56c9-4a2f-cb50-173633d296da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.2/623.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for opendelta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for web.py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/thunlp/OpenDelta.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOwAdIRUIKh"
      },
      "source": [
        "Use `OpenDelta` library to do the same thing. [link](https://opendelta.readthedocs.io/en/latest/modules/deltas.html)\n",
        "\n",
        "For hyperparameters, test with `N_SOFT_PROMPT_TOKENS=10` and `N_SOFT_PROMPT_TOKENS=20` and report them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LiNnIlRlUFyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2f88c7-1903-45f9-d73c-4eeeeb6a9676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [01:37<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.47055563601580536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:46<16:02, 106.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.45777927835782367\n",
            "F1 Score (Weighted): 0.210237813239944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [03:29<16:02, 106.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.45463508877524716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [03:38<14:38, 109.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.431967222329342\n",
            "F1 Score (Weighted): 0.3385504417148931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [05:22<14:38, 109.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4416408994618584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [05:32<12:59, 111.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4221643814534852\n",
            "F1 Score (Weighted): 0.4219660011359126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [07:16<12:59, 111.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.43438523083447134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [07:26<11:15, 112.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4184220243584026\n",
            "F1 Score (Weighted): 0.39062596024868373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [09:12<11:15, 112.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.42939041299934694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [09:22<09:28, 113.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4185719056562944\n",
            "F1 Score (Weighted): 0.36932117002774456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [11:08<09:28, 113.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.42765822743668275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [11:18<07:37, 114.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4079696806994351\n",
            "F1 Score (Weighted): 0.3931445753551571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [13:03<07:37, 114.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.42585558559805314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [13:13<05:44, 114.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40546070355357544\n",
            "F1 Score (Weighted): 0.386346827057252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:59<05:44, 114.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.4243841072454809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [15:09<03:50, 115.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39690240133892407\n",
            "F1 Score (Weighted): 0.4524846149688576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [16:56<03:50, 115.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.4225602915739631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [17:06<01:55, 115.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39909834663073224\n",
            "F1 Score (Weighted): 0.40306679263020806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [18:52<01:55, 115.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.42106350419674327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [19:02<00:00, 114.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3918967906272773\n",
            "F1 Score (Weighted): 0.4486783285676869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from opendelta.delta_models.soft_prompt import SoftPromptModel\n",
        "from transformers import AdamW\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CONFIG.model_name,\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        "    )\n",
        "\n",
        "model_soft_prompt_10 = SoftPromptModel(\n",
        "    backbone_model=model,\n",
        "    soft_token_num=10,\n",
        "    init_range=0.5,\n",
        "    token_init=True,\n",
        "    other_expand_ids={\"attention_mask\": 1, \"token_type_ids\": 0},\n",
        "    modified_modules=[\"root\"],\n",
        ")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    if \"soft\" in name:\n",
        "      param.requires_grad = True\n",
        "\n",
        "model = model.to(CONFIG.device)\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)\n",
        "\n",
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CONFIG.model_name,\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        "    )\n",
        "\n",
        "model_soft_prompt_20 = SoftPromptModel(\n",
        "    backbone_model=model,\n",
        "    soft_token_num=20,\n",
        "    init_range=0.5,\n",
        "    token_init=True,\n",
        "    other_expand_ids={\"attention_mask\": 1, \"token_type_ids\": 0},\n",
        "    modified_modules=[\"root\"],\n",
        ")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    if \"soft\" in name:\n",
        "      param.requires_grad = True\n",
        "\n",
        "model = model.to(CONFIG.device)\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)\n",
        "\n",
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD11fFE45aC-",
        "outputId": "1329a5b5-ecc3-459f-ffc5-72ac36e23691"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [01:56<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.47137393447804576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [02:07<19:04, 127.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.46013085679574445\n",
            "F1 Score (Weighted): 0.21466794468857534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [04:05<19:04, 127.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.44795159031363097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [04:15<17:04, 128.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4281088917544394\n",
            "F1 Score (Weighted): 0.3447256082473785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [06:14<17:04, 128.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.43002303223558924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [06:25<15:01, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40940046220114734\n",
            "F1 Score (Weighted): 0.41848133052028325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [08:24<15:01, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.42366501067411455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [08:35<12:55, 129.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40359138719963306\n",
            "F1 Score (Weighted): 0.428385608799628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [10:34<12:55, 129.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.4180602641666637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [10:45<10:47, 129.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40053410963578656\n",
            "F1 Score (Weighted): 0.4418092744540763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [12:44<10:47, 129.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.4141716056647785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [12:55<08:38, 129.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3994808160897457\n",
            "F1 Score (Weighted): 0.4367551571176264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [14:54<08:38, 129.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.41268796501631405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [15:05<06:29, 129.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4001951145403313\n",
            "F1 Score (Weighted): 0.44152446666056167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [17:04<06:29, 129.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.40713458958475346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [17:14<04:19, 129.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39055857152649853\n",
            "F1 Score (Weighted): 0.46640415465471274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [19:13<04:19, 129.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.4046679708887549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [19:24<02:09, 129.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3996859815987674\n",
            "F1 Score (Weighted): 0.45092310857887374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [21:22<02:09, 129.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.4026825452711493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [21:33<00:00, 129.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3912365021127643\n",
            "F1 Score (Weighted): 0.481628160468963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f21bfde816a44bda9ff7e01ecf85d735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba964d1bb5cd4bdf9e97c1e11ab8189a",
              "IPY_MODEL_4b31a8abc501456f8ec737a265bb18c3",
              "IPY_MODEL_7e3e74c8b15a4bb78a76a346fa2526e2"
            ],
            "layout": "IPY_MODEL_bfca75c98a344a96a1cab791f90620c6"
          }
        },
        "ba964d1bb5cd4bdf9e97c1e11ab8189a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9d42243fe544eb9943c2d424a96a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_60c9cbd754ca4af2b802e8a1e2083924",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4b31a8abc501456f8ec737a265bb18c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e1003f687241c9a30463d436d98115",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6744263251a44d88662e6fe223dcf06",
            "value": 654226731
          }
        },
        "7e3e74c8b15a4bb78a76a346fa2526e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb71ec5662164879ac517842b2c388eb",
            "placeholder": "​",
            "style": "IPY_MODEL_88bfd33c5b5049e087ef70e9a9481e09",
            "value": " 654M/654M [00:16&lt;00:00, 45.6MB/s]"
          }
        },
        "bfca75c98a344a96a1cab791f90620c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9d42243fe544eb9943c2d424a96a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c9cbd754ca4af2b802e8a1e2083924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e1003f687241c9a30463d436d98115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6744263251a44d88662e6fe223dcf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb71ec5662164879ac517842b2c388eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88bfd33c5b5049e087ef70e9a9481e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}